[toc]

### 1.4.2　检查网站地图

网站提供的 `Sitemap` 文件（即网站地图）可以帮助爬虫定位网站最新的内容，而无须爬取每一个网页。如果想要了解更多信息，可以从 `http://www.sitemaps.org/protocol.html` 获取网站地图标准的定义。许多网站发布平台都有自动生成网站地图的能力。下面是在 `robots.txt` 文件中定位到的 `Sitemap` 文件的内容。

```python
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <url><loc>http://example.python-scraping.com/view/Afghanistan-1</loc>
  </url>
  <url><loc>http://example.python-scraping.com/view/Aland-Islands-2</loc>
  </url>
  <url><loc>http://example.python-scraping.com/view/Albania-3</loc>
  </url>
  ...
</urlset>
```

网站地图提供了所有网页的链接，我们会在后面的小节中使用这些信息，用于创建我们的第一个爬虫。虽然 `Sitemap` 文件提供了一种爬取网站的有效方式，但是我们仍需对其谨慎处理，因为该文件可能存在缺失、过期或不完整的问题。

