[toc]

### 第3章　下载缓存

在上一章中，我们学习了如何从已爬取到的网页中抓取数据，以及将抓取结果保存到CSV文件中。如果我们还想抓取另外一个字段，比如国旗图片的URL，那么又该怎么做呢？要想抓取这些新增的字段，我们需要重新下载整个网站。对于我们这个小型的示例网站而言，这可能不算特别大的问题。但是，对于那些拥有数百万个网页的网站来说，重新爬取可能需要耗费几个星期的时间。爬虫避免此类问题的方式之一是从开始时就缓存被爬取的网页，这样就可以让每个网页只下载一次。

在本章中，我们将介绍几种使用网络爬虫实现该目标的方式。

在本章中，我们将介绍如下主题：

+ 何时使用缓存；
+ 为链接爬虫添加缓存支持；
+ 测试缓存；
+ 使用requests-cache；
+ 实现Redis缓存。

