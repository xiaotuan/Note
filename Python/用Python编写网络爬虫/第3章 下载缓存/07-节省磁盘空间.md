[toc]

### 3.3.3　节省磁盘空间

为了最小化缓存所需的磁盘空间，我们可以对下载得到的HTML文件进行压缩处理。处理的实现方法很简单，只需在保存到磁盘之前使用 `zlib` 压缩序列化字符串即可。使用当前实现有助于人类阅读这些文件。我可以阅读任意缓存页面，并以JSON格式查看字典。如果需要的话，我还可以复用这些文件，将它们移至不同的操作系统中，用于非Python代码。添加压缩将使这些文件不再打开即可阅读，而且当我们通过其他编码语言使用下载的文件时，可能会引入一些编码问题。为了能够启用和关闭压缩，我们将其添加到构造函数中，并与文件编码（默认值设为UTF-8）一起使用。

```python
class DiskCache:
    def __init__(self, cache_dir='../data/cache', max_len=255,
compress=True,
                 encoding='utf-8'):
        ...
        self.compress = compress
        self.encoding = encoding
```

然后，需要更新 `__getitem__` 和 `__setitem__` 方法。

```python
# in __getitem__ method for DiskCache class
mode = ('rb' if self.compress else 'r')
with open(path, mode) as fp:
    if self.compress:
        data = zlib.decompress(fp.read()).decode(self.encoding)
        return json.loads(data)
    return json.load(fp)
# in __setitem__ method for DiskCache class
mode = ('wb' if self.compress else 'w')
with open(path, mode) as fp:
    if self.compress:
        data = bytes(json.dumps(result), self.encoding)
        fp.write(zlib.compress(data))
else:
json.dump(result, fp)
```

压缩完所有网页之后，缓存大小从416KB下降到156KB，而在我的计算机上爬取缓存示例网站的时间是260毫秒。

根据你的操作系统和Python安装的不同，等待时间可能会略长于未压缩的缓存（我这里实际更短）。根据约束的优先级不同（速度与内存、调试的方便性等），需要对你的爬虫是否使用压缩做出明智而慎重的决策。

你可以在本书代码库中查看更新了的磁盘缓存代码，它位于本书源码的chp3文件夹中，其名为 `diskcache.py` 。

