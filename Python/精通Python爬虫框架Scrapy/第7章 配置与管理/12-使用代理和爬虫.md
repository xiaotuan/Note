### 7.2.9　使用代理和爬虫

Scrapy的 `HttpProxyMiddleware` 组件允许你使用代理设置，根据UNIX约定，这些设置是通过 `http_proxy` 、 `https_proxy` 以及 `no_proxy` 这几个环境变量定义的。该组件默认是启用状态的。

#### 示例4——使用代理和Crawlera的智能代理

DynDNS（或任何类似的服务）提供了一个免费的在线工具，用于查看当前的IP地址。使用Scrapy shell，我们向 `checkip.dyndns.org` 发送请求，查看响应，获取当前的IP地址。

```python
$ scrapy shell http://checkip.dyndns.org
>>> response.body
'<html><head><title>Current IP Check</title></head><body>Current IP 
Address: xxx.xxx.xxx.xxx</body></html>\r\n'
>>> exit( )

```

想要开始代理请求，需要退出shell，并使用 `export` 命令设置新的代理。可以通过搜索HMA的公开代理列表测试免费代理（ `http://proxylist. hidemyass.com` ）。比如，我们从该列表中选择了一个IP为10.10.1.1、端口为80的代理（非真实存在的代理，请将其替换为你自己的代理地址），可以按照如下操作。

```python
$ # First check if you already use a proxy
$ env | grep http_proxy
$ # We should have nothing. Now let's set a proxy
$ export http_proxy=http://10.10.1.1:80

```

按照刚才的步骤重新运行scrapy shell，可以看到执行的请求使用了不同的IP。此外，你还会发现这些代理通常速度都很慢，而且在一些情况下无法成功，如果遇到这类情况，可以尝试更换为其他的代理。如果想要禁用代理，则需要退出Scrapy shell，并执行 `unset http_proxy` （或恢复为之前的值）。

Crawlera是Scrapinghub的一项服务，可以为Scrapy的开发者提供一个非常智能的代理。除了在后台使用很大的IP池路由你的请求外，该代理还会调整延迟和失败重试，让你在保持尽可能快的情况下，获得尽可能多且稳定的成功响应流。它基本上可以使爬虫开发者的梦想成真，并且只需像之前那样，设置 `http_proxy` 环境变量，就可以使用。

```python
$ export http_proxy=myusername:mypassword@proxy.crawlera.com:8010

```

除了HTTP代理外，Crawlera还可以通过Scrapy的中间件组件方式使用。

