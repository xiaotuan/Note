### 1.5　在充满爬虫的世界里做一个好公民

当开发爬虫时，还有一些事情需要清楚。不负责任的网络爬虫会令人不悦，甚至在某些情况下是违法的。有两个非常重要的事情是避免类似 **拒绝服务** （ **DoS** ）攻击的行为以及侵犯版权。

对于第一种情况，一个典型的访问者可能每几秒访问一个新的页面。而一个典型的网络爬虫则可能每秒下载数十个页面。这样就比典型用户产生的流量多出了10倍以上。这可能会使网站所有者非常不高兴。请使用流量限速将你产生的流量减少到可以接受的普通用户的水平。此外，还应该监控响应时间，如果发现响应时间增加了，就需要降低爬虫的强度。好消息是Scrapy对于这些功能都提供了开箱即用的实现（参见第7章）。

对于版权问题，显然你需要看一下你抓取的每个网站的版权声明，并确保你理解其允许做什么，不允许做什么。大多数网站都允许你处理其站点的信息，只要不以自己的名义重新发布即可。在你的请求中，有一个很好的 `User-Agent` 字段，它可以让网站管理员知道你是谁，你用他们的数据做什么。Scrapy在制造请求时，默认使用 `BOT_NAME` 参数作为 `User-Agent` 。如果 `User-Agent` 是一个URL或者能够指明你的应用名称，那么网站管理员可以通过访问你的站点，更多地了解你是如何使用他们的数据的。另一个非常重要的方面是，请允许任何网站管理员阻止你访问其网站的指定区域。对于基于Web标准的 `robots.txt` 文件（参见<a class="my_markdown" href="['http://www.google.com/robots.txt']">http://www.google.com/robots.txt</a>的文件示例），Scrapy提供了用于尊重网站管理员设置的功能（ `RobotsTxtMiddleware` ）。最后，最好向网站管理员提供一些方法，让他们能说明不希望在你的爬虫中出现的东西。至少网站管理员必须能够很容易地找到和你交流及表达顾虑的方式。

