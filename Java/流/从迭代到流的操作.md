假如，假设我们想要对某本书中的所有长单词进行计数。首先，将所有单词放到一个列表中：

```java
String contents = new String(Files.readAllBytes(Paths.get("alice.txt")), StandardCharsets.UTF_8);	// Read file into string
List<String> words = Arrays.asList(contents.split("\\PL+"));	// Split into words; nonletters are delimiters

// 现在，我们可以迭代它了
long count = 0;
for (String w : words) {
    if (w.length() > 12) {
        count++;
    }
}
// 在使用流时，相同的操作看起来像下面这样
long count = words.stream()
    .filter(w -> w.length() > 12)
    .count();
```

仅将 `stream` 修改为 `parallelStream` 就可以让流库以并行方式来执行过滤和计数。

```java
long count = words.parallelStream()
    .filter(w -> w.length() > 12)
    .count();
```

流操作的典型流程如下：

1.   创建一个流。
2.   指定将初始流转换位其他六的中间操作，可能包含多个步骤。
3.   应用终止操作，从而产生结果。这个操作会强制执行之前的惰性操作。从此之后，这个流就再也不能用了。

**示例代码：**

```java
import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.Arrays;
import java.util.List;

public class CountLongWords {
	
	public static void main(String[] args) throws IOException {
		String contents = new String(Files.readAllBytes(Paths.get("./src/CountLongWords.java")),
				StandardCharsets.UTF_8);
		List<String> words = Arrays.asList(contents.split("\\PL+"));
		
		long count = 0;
		for (String w : words) {
			if (w.length() > 12) {
				count++;
			}
		}
		System.out.println(count);
		
		count = words.stream().filter(w -> w.length() > 12).count();
		System.out.println(count);
		
		count = words.parallelStream().filter(w -> w.length() > 12).count();
		System.out.println(count);
	}

}
```

